---

## ğŸ“Š 1. Analysis of Algorithms
- **Definition**: The process of determining the efficiency of an algorithm in terms of time and space.
- **Why it matters**: Two algorithms may solve the same problem, but one could be 100Ã— faster or use far less memory.
- **Key aspects**:
  - **Time Complexity** â†’ How execution time grows with input size.
  - **Space Complexity** â†’ How much memory is required.
  - **Correctness** â†’ Does it always produce the right result?
  - **Scalability** â†’ How it behaves as input grows very large.

---

## ğŸ” 2. Analysis of Common Loops & Recursion
### Loops
- **Single loop**:  
  cpp
  for (int i = 0; i < n; i++) { ... }
  
  â†’ Runs **n times** â†’ **O(n)**.
- **Nested loop**:  
  cpp
  for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) { ... }
  }
 
  â†’ Runs **n Ã— n = nÂ² times** â†’ **O(nÂ²)**.
- **Dependent loop**:  
 cpp
  for (int i = 0; i < n; i++) {
      for (int j = 0; j < i; j++) { ... }
  }
 
  â†’ Runs **1 + 2 + â€¦ + n â‰ˆ nÂ²/2** â†’ **O(nÂ²)**.

### Recursion
- **Example**: Factorial  
  cpp
  int fact(int n) {
      if (n == 0) return 1;
      return n * fact(n-1);
  }
 
  - Each call reduces `n` by 1 â†’ **n calls** â†’ **O(n)**.
- **Divide & Conquer Example**: Merge Sort  
  - Splits array into halves â†’ recurrence:  
    $$T(n) = 2T(n/2) + O(n)$$  
    â†’ Solves to **O(n log n)**.

---

## âˆ 3. Asymptotic Notation
Used to describe performance as input size â†’ âˆ.

- **Big-O (O)** â†’ *Upper bound* (worst case).  
  Example: Linear search â†’ **O(n)**.
- **Big-Î© (Î©)** â†’ *Lower bound* (best case).  
  Example: Linear search (if element is first) â†’ **Î©(1)**.
- **Big-Î˜ (Î˜)** â†’ *Tight bound* (average case).  
  Example: Linear search â†’ **Î˜(n)**.

---

## ğŸ’¾ 4. Space Complexity
- **Definition**: Total memory used by an algorithm.
- **Components**:
  - **Fixed part** â†’ constants, program code, etc.
  - **Variable part** â†’ input data, recursion stack, dynamic allocations.
- **Examples**:
  - Iterative Fibonacci â†’ **O(1)** space.
  - Recursive Fibonacci â†’ **O(n)** space (due to call stack).

---

## ğŸ“ˆ 5. Order of Growth
- **Definition**: How runtime grows relative to input size.
- **Common orders**:
  | Growth | Example | Efficiency |
  |--------|---------|------------|
  | O(1)   | Accessing array element | Excellent |
  | O(log n) | Binary search | Very good |
  | O(n)   | Linear search | Good |
  | O(n log n) | Merge sort | Efficient |
  | O(nÂ²)  | Bubble sort | Poor for large n |
  | O(2â¿)  | Recursive subset generation | Very poor |
  | O(n!)  | Traveling salesman brute force | Impractical |

---

âœ… **Quick mental model**:  
- Loops â†’ count iterations.  
- Recursion â†’ write recurrence relation.  
- Asymptotics â†’ ignore constants & small terms.  
- Space â†’ track variables + recursion depth.  
- Order of growth â†’ compare how fast functions blow up.

---

# âš¡ DSA Analysis Cheat Sheet

## 1. Analysis of Algorithms
- **Goal**: Measure efficiency in **time** and **space**.
- **Focus**:  
  - Time Complexity â†’ growth of execution steps.  
  - Space Complexity â†’ memory usage.  
  - Correctness & scalability.

---

## 2. Common Loop Patterns
| Code Pattern | Iterations | Complexity |
|--------------|------------|------------|
| `for (i=0; i<n; i++)` | n | **O(n)** |
| Nested: `for (i=0; i<n; i++) for (j=0; j<n; j++)` | n Ã— n | **O(nÂ²)** |
| Dependent: `for (i=0; i<n; i++) for (j=0; j<i; j++)` | 1+2+â€¦+n â‰ˆ nÂ²/2 | **O(nÂ²)** |
| Doubling: `for (i=1; i<n; i*=2)` | logâ‚‚n | **O(log n)** |

---

## 3. Recursion Analysis
- **Method**: Write recurrence relation.
- **Examples**:
  - Factorial:  
    $$T(n) = T(n-1) + O(1) \implies O(n)$$
  - Merge Sort:  
    $$T(n) = 2T(n/2) + O(n) \implies O(n \log n)$$
  - Fibonacci (naÃ¯ve recursion):  
    $$T(n) = T(n-1) + T(n-2) + O(1) \implies O(2^n)$$

---

## 4. Asymptotic Notation
- **Big-O (O)** â†’ Worst-case upper bound.  
- **Big-Î© (Î©)** â†’ Best-case lower bound.  
- **Big-Î˜ (Î˜)** â†’ Tight bound (average case).  

ğŸ‘‰ Ignore constants & lower-order terms.  
Example: `3nÂ² + 5n + 10 â†’ O(nÂ²)`.

---

## 5. Space Complexity
- **Components**:
  - Fixed part â†’ constants, code.  
  - Variable part â†’ input, recursion stack, dynamic memory.
- **Examples**:
  - Iterative Fibonacci â†’ O(1).  
  - Recursive Fibonacci â†’ O(n) (stack depth).  
  - Merge Sort â†’ O(n) (extra arrays).

---

## 6. Order of Growth (Hierarchy)
| Growth | Example | Practicality |
|--------|---------|--------------|
| O(1)   | Array access | Excellent |
| O(log n) | Binary search | Very good |
| O(n)   | Linear search | Good |
| O(n log n) | Merge/Quick sort | Efficient |
| O(nÂ²)  | Bubble/Insertion sort | Poor for large n |
| O(2â¿)  | Recursive subsets | Impractical |
| O(n!)  | Brute-force TSP | Impossible for large n |

---

## ğŸ”‘ Quick Rules of Thumb
- **Loop count = time complexity.**
- **Recursion = recurrence relation.**
- **Drop constants & small terms.**
- **Space = variables + recursion depth.**
- **Compare growth rates to judge scalability.**

---
